{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Credit Card Applications (Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Library for Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ActivationDoesNotExist(Exception):\n",
    "    \"\"\"Valid activations are sigmoid, tanh, and relu, provided as a string\"\"\"\n",
    "    pass\n",
    "\n",
    "class InputDimensionNotCorrect(Exception):\n",
    "    \"\"\"Need to specify input dimension, i.e. input shape into the first layer\"\"\"\n",
    "    pass\n",
    "\n",
    "class LossFunctionNotDefined(Exception):\n",
    "    \"\"\"Loss function in cost() method not defined\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DenseLayer:\n",
    "    \"\"\"\n",
    "    A class to define fully connected layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, inputDimension, units, activation='', randomMultiplier=0.01):\n",
    "        \"\"\"\n",
    "        Constructor:\n",
    "          inputDimension: number of input features\n",
    "          units: number of neurons in the layer\n",
    "          activation: activation function applied to layer\n",
    "            - options: 'sigmoid', 'tanh', 'relu', ''\n",
    "          randomMultiplier: multiplier applied to the random weights during initialization\n",
    "        \"\"\"\n",
    "        self.weights, self.bias = self.initialize(inputDimension, units, randomMultiplier)\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = activation\n",
    "            self.activationForward = self.sigmoid\n",
    "            self.activationBackward = self.sigmoidGrad\n",
    "        elif activation == 'relu':\n",
    "            self.activation = activation\n",
    "            self.activationForward = self.relu\n",
    "            self.activationBackward = self.reluGrad\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = activation\n",
    "            self.activationForward = self.tanh\n",
    "            self.activationBackward = self.tanhGrad\n",
    "        elif activation != '':\n",
    "            raise ActivationDoesNotExist\n",
    "        else:\n",
    "            self.activation = 'none'\n",
    "            self.activationForward = self.linear\n",
    "            self.activationBackward = self.linear\n",
    "    \n",
    "    def initialize(self, nx, nh, randomMultiplier):\n",
    "        \"\"\"\n",
    "        Initializes weights randomly:\n",
    "          nx: number of input features\n",
    "          nh: number of units\n",
    "          randomMultiplier: multiplier applied to the random weights during initialization\n",
    "        returns:\n",
    "          weights: the randomly initialized weights\n",
    "          bias: the bias terms\n",
    "        \"\"\"\n",
    "        weights = randomMultiplier * np.random.randn(nh, nx)\n",
    "        bias = np.zeros([nh, 1])\n",
    "        return weights, bias\n",
    "\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function\n",
    "        \"\"\"\n",
    "        A = 1 / (1 + np.exp(-Z))\n",
    "        return A\n",
    "        \n",
    "    def sigmoidGrad(self, dA):\n",
    "        \"\"\"\n",
    "        Differential of sigmoid function with chain rule applied\n",
    "        \"\"\"\n",
    "        s = 1 / (1 + np.exp(-self.prevZ))\n",
    "        dZ = dA * s * (1 - s)\n",
    "        return dZ\n",
    "    \n",
    "    \n",
    "    def relu(self, Z):\n",
    "        \"\"\"\n",
    "        Relu activation function\n",
    "        \"\"\"\n",
    "        A = np.maximum(0, Z)\n",
    "        return A\n",
    "        \n",
    "    def reluGrad(self, dA):\n",
    "        \"\"\"\n",
    "        Differential of relu function with chain rule applied\n",
    "        \"\"\"\n",
    "        s = np.maximum(0, self.prevZ)\n",
    "        dZ = (s>0) * 1 * dA\n",
    "        return dZ \n",
    "\n",
    "        \n",
    "    def tanh(self, Z):\n",
    "        \"\"\"\n",
    "        Tanh activation function\n",
    "        \"\"\"\n",
    "        A = np.tanh(Z)\n",
    "        return A\n",
    "\n",
    "    def tanhGrad(self, dA):\n",
    "        \"\"\"\n",
    "        Differential of tanh function with chain rule applied\n",
    "        \"\"\"\n",
    "        s = np.tanh(self.prevZ)\n",
    "        dZ = (1 - s**2) * dA\n",
    "        return dZ\n",
    "\n",
    "\n",
    "    def linear(self, Z):\n",
    "        \"\"\"\n",
    "        Placeholder when no activation function is used\n",
    "        \"\"\"\n",
    "        return Z\n",
    "        \n",
    "    \n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        Forward pass through layer\n",
    "          A: input vector\n",
    "        \"\"\"\n",
    "        Z = np.dot(self.weights, A) + self.bias\n",
    "        self.prevZ = Z\n",
    "        self.prevA = A\n",
    "        A = self.activationForward(Z)\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backward pass through layer\n",
    "          dA: previous gradient\n",
    "        \"\"\"\n",
    "        dZ = self.activationBackward(dA)\n",
    "        m = self.prevA.shape[1]\n",
    "        self.dW = 1 / m * np.dot(dZ, self.prevA.T)\n",
    "        self.db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        prevdA = np.dot(self.weights.T, dZ)\n",
    "        return prevdA\n",
    "    \n",
    "    \n",
    "    def update(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update weights using gradients from backward pass\n",
    "          learning_rate: the learning rate used in the gradient descent\n",
    "        \"\"\"\n",
    "        self.weights = self.weights - learning_rate * self.dW\n",
    "        self.bias = self.bias - learning_rate * self.db\n",
    "\n",
    "        \n",
    "    def outputDimension(self):\n",
    "        \"\"\"\n",
    "        Returns the output dimension for the next layer\n",
    "        \"\"\"\n",
    "        return len(self.bias)\n",
    "\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Used to print a pretty summary of the layer\n",
    "        \"\"\"\n",
    "        act = 'none' if self.activation == '' else self.activation\n",
    "        return f'Dense layer (nx={self.weights.shape[1]}, nh={self.weights.shape[0]}, activation={act})'\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Neural Network structure that holds our layers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loss='cross-entropy', randomMultiplier = 0.01):\n",
    "        \"\"\"\n",
    "        Constructor:\n",
    "          loss: the loss function. Two are defined:\n",
    "             - 'cross-entropy' and 'mean-square-error'\n",
    "          randomMultiplier: multiplier applied to the random weights during initialization\n",
    "        \"\"\"\n",
    "        self.layers=[]\n",
    "        self.randomMultiplier = randomMultiplier\n",
    "        if loss=='cross-entropy':\n",
    "            self.lossFunction = self.crossEntropyLoss\n",
    "            self.lossBackward = self.crossEntropyLossGrad\n",
    "        elif loss=='mean-square-error':\n",
    "            self.lossFunction = self.meanSquareError\n",
    "            self.lossBackward = self.meanSquareErrorGrad\n",
    "        else:\n",
    "            raise LossFunctionNotDefined\n",
    "        self.loss=loss\n",
    "\n",
    "\n",
    "    def addLayer(self, inputDimension=None, units=1, activation=''):\n",
    "        \"\"\"\n",
    "        Adds a Dense layer to the network:\n",
    "          inputDimension: required when it is the first layer. otherwise takes dimensions of previous layer.\n",
    "          units: number of neurons in the layer\n",
    "          activation: activation function: valid choices are: 'sigmoid', 'tanh', 'relu', ''\n",
    "        \"\"\"\n",
    "        if (inputDimension is None):\n",
    "            if (len(self.layers)==0):\n",
    "                raise InputDimensionNotCorrect\n",
    "            inputDimension=self.layers[-1].outputDimension()\n",
    "        layer = DenseLayer(inputDimension, units, activation, randomMultiplier= self.randomMultiplier)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def crossEntropyLoss(self, Y, A, epsilon=1e-15):\n",
    "        \"\"\"\n",
    "        Cross Entropy loss function\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "          epsilon: small value to make minimize chance for log(0) error\n",
    "        \"\"\"\n",
    "        m = Y.shape[1]\n",
    "        loss = -1 * (Y * np.log(A + epsilon) + (1 - Y) * np.log(1 - A + epsilon))\n",
    "        cost = 1 / m * np.sum(loss)\n",
    "        return np.squeeze(cost)\n",
    "            \n",
    "    def crossEntropyLossGrad(self, Y, A):\n",
    "        \"\"\"\n",
    "        Cross Entropy loss Gradient\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "        \"\"\"\n",
    "        dA = -(np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "        return dA\n",
    "    \n",
    "    \n",
    "    def meanSquareError(self, Y, A):\n",
    "        \"\"\"\n",
    "        Mean square error loss function\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "        \"\"\"\n",
    "        loss = np.square(Y - A)\n",
    "        m = Y.shape[1]\n",
    "        cost = 1 / m * np.sum(loss)\n",
    "        return np.squeeze(cost)\n",
    "    \n",
    "    def meanSquareErrorGrad(self, Y, A):\n",
    "        \"\"\"\n",
    "        Mean square error loss gradient\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "        \"\"\"\n",
    "        dA = -2 * (Y - A)\n",
    "        return dA\n",
    "\n",
    "    \n",
    "    def cost(self, Y, A):\n",
    "        \"\"\"\n",
    "        Cost function wrapper\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "        \"\"\"\n",
    "        return self.lossFunction(Y, A)\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through the whole model.\n",
    "          X: input vector\n",
    "        \"\"\"\n",
    "        x = np.copy(X)\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "            \n",
    "    \n",
    "    def backward(self, A, Y):\n",
    "        \"\"\"\n",
    "        backward pass through the whole model\n",
    "          Y: true labels\n",
    "          A: final activation function (predicted labels)\n",
    "        \"\"\"\n",
    "        dA = self.lossBackward(Y, A)\n",
    "        for layer in reversed(self.layers):\n",
    "            dA = layer.backward(dA)\n",
    "    \n",
    "    \n",
    "    def update(self, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Update weights and do a step of gradient descent for the whole model.\n",
    "          learning_rate: learning_rate to use\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            layer.update(learning_rate)\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Pretty print the model\n",
    "        \"\"\"\n",
    "        layrepr = ['  ' + str(ix+1)+' -> ' + str(x) for ix, x in enumerate(self.layers)]\n",
    "        return '[\\n' + '\\n'.join(layrepr) + '\\n]'\n",
    "   \n",
    "    \n",
    "    def numberOfParameters(self):\n",
    "        \"\"\"\n",
    "        Print number of trainable parameters in the model\n",
    "        \"\"\"\n",
    "        n = 0\n",
    "        for layer in self.layers:\n",
    "            n += np.size(layer.weights) + len(layer.bias)\n",
    "        print(f'There are {n} trainable parameters in the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>YEARS_OLD</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5008804</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5008804</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5008804</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5008804</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5008804</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       ID FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
       "0           0  5008804            Y               Y          427500.0   \n",
       "1           1  5008804            Y               Y          427500.0   \n",
       "2           2  5008804            Y               Y          427500.0   \n",
       "3           3  5008804            Y               Y          427500.0   \n",
       "4           4  5008804            Y               Y          427500.0   \n",
       "\n",
       "  NAME_INCOME_TYPE NAME_EDUCATION_TYPE NAME_FAMILY_STATUS NAME_HOUSING_TYPE  \\\n",
       "0          Working    Higher education     Civil marriage  Rented apartment   \n",
       "1          Working    Higher education     Civil marriage  Rented apartment   \n",
       "2          Working    Higher education     Civil marriage  Rented apartment   \n",
       "3          Working    Higher education     Civil marriage  Rented apartment   \n",
       "4          Working    Higher education     Civil marriage  Rented apartment   \n",
       "\n",
       "   YEARS_OLD  DAYS_EMPLOYED  MONTHS_BALANCE  STATUS  \n",
       "0       32.0         4542.0            -0.0       1  \n",
       "1       32.0         4542.0             1.0       1  \n",
       "2       32.0         4542.0             2.0       1  \n",
       "3       32.0         4542.0             3.0       1  \n",
       "4       32.0         4542.0             4.0       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the dataset to be used\n",
    "df1 = pd.read_csv(\"updatedMergedApplicationCreditRecords.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Y</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Y</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Y</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Y</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLAG_OWN_REALTY  AMT_INCOME_TOTAL  DAYS_EMPLOYED  MONTHS_BALANCE  STATUS\n",
       "0                Y          427500.0         4542.0            -0.0       1\n",
       "16               Y          427500.0         4542.0            -0.0       1\n",
       "31               Y          112500.0         1134.0            -0.0       1\n",
       "61               Y          270000.0         3051.0            -0.0       1\n",
       "66               Y          270000.0         3051.0            22.0       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin by removing duplicates and pruning columns we determined in the Unsupervised Learning step to be unhelpful\n",
    "df1 = df1.drop_duplicates(\"ID\")\n",
    "df1 = df1.drop(columns=[\"Unnamed: 0\", \"ID\", \"FLAG_OWN_CAR\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\", \"YEARS_OLD\"])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO_REALTY</th>\n",
       "      <th>YES_REALTY</th>\n",
       "      <th>TOTAL_INCOME</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.970676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.970676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055233</td>\n",
       "      <td>0.961730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156977</td>\n",
       "      <td>0.966763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156977</td>\n",
       "      <td>0.966763</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NO_REALTY  YES_REALTY  TOTAL_INCOME  DAYS_EMPLOYED  MONTHS_BALANCE  STATUS\n",
       "0        0.0         1.0      0.258721       0.970676        0.000000     1.0\n",
       "1        0.0         1.0      0.258721       0.970676        0.000000     1.0\n",
       "2        0.0         1.0      0.055233       0.961730        0.000000     1.0\n",
       "3        0.0         1.0      0.156977       0.966763        0.000000     1.0\n",
       "4        0.0         1.0      0.156977       0.966763        0.366667     1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a OneHotEncoder for our FLAG_OWN_REALTY column\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Start OneHotEncoding Process\n",
    "encoder = make_column_transformer((OneHotEncoder(), [\"FLAG_OWN_REALTY\"]), remainder=\"passthrough\")\n",
    "encoded = encoder.fit_transform(df1)\n",
    "encoded_dataset = pd.DataFrame(encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "#Fix up the encoded column names\n",
    "encoded_dataset.rename(columns= {\"onehotencoder__FLAG_OWN_REALTY_N\":\"NO_REALTY\",\n",
    "                                \"onehotencoder__FLAG_OWN_REALTY_Y\":\"YES_REALTY\",\n",
    "                                \"remainder__AMT_INCOME_TOTAL\":\"TOTAL_INCOME\",\n",
    "                                \"remainder__DAYS_EMPLOYED\":\"DAYS_EMPLOYED\",\n",
    "                                \"remainder__MONTHS_BALANCE\":\"MONTHS_BALANCE\",\n",
    "                                \"remainder__STATUS\":\"STATUS\"}, inplace = True)\n",
    "\n",
    "#encoded_dataset.head()\n",
    "\n",
    "#Begin normalization process\n",
    "minMax = MinMaxScaler()\n",
    "encoded_dataset[[\"TOTAL_INCOME\", \"DAYS_EMPLOYED\", \"MONTHS_BALANCE\"]] = minMax.fit_transform(encoded_dataset[[\"TOTAL_INCOME\", \"DAYS_EMPLOYED\", \"MONTHS_BALANCE\"]])\n",
    "\n",
    "#encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and Testing the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/null/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = encoded_dataset.drop([\"STATUS\"], axis=1)\n",
    "Y = encoded_dataset[[\"STATUS\"]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=5)\n",
    "\n",
    "mlp = MLPClassifier(solver = \"sgd\", random_state = 42, activation = \"logistic\", learning_rate_init = 0.3, hidden_layer_sizes = (6, 3), max_iter = 500)\n",
    "mlp.fit(X_train, Y_train)\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      " Accuracy of Model:  0.989687328579265\n",
      "Mean Squared Error:  0.010312671420735052\n",
      "\n",
      " Precision and Recall\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        94\n",
      "         1.0       0.99      1.00      0.99      9021\n",
      "\n",
      "    accuracy                           0.99      9115\n",
      "   macro avg       0.49      0.50      0.50      9115\n",
      "weighted avg       0.98      0.99      0.98      9115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/null/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/null/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/null/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "confusion_matrix(Y_test, predictions)\n",
    "\n",
    "#Accuracy and MSE of model\n",
    "print(\"\\n Accuracy of Model: \", accuracy_score(Y_test, predictions))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(Y_test, predictions))\n",
    "\n",
    "#Precision and Recall\n",
    "print(\"\\n Precision and Recall\")\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989687328579265\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#Saving the model for future use\n",
    "FFNN = \"FFNN_model.sav\"\n",
    "pickle.dump(mlp, open(FFNN, \"wb\"))\n",
    "\n",
    "#Load the model for use\n",
    "#premade_model = pickle.load(open(\"FFNN_model.sav\", \"rb\"))\n",
    "#result = premade_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49f6107ad89c9c7fd79771d3dfcfde8fadaa90041805bc57f3ce6040a6e5d26c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
